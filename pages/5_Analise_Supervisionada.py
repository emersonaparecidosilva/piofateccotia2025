import streamlit as st
import pandas as pd
from utils import check_password

if not check_password():
    st.stop()

st.set_page_config(page_title="An√°lise Supervisionada", page_icon="üß†", layout="wide")
st.title("üß† An√°lise de Algoritmos de Aprendizado Supervisionado")
st.markdown("---")

# --- SE√á√ÉO 1: O EXPERIMENTO PRINCIPAL (MUNDO REAL) ---

st.header("Metodologia (Abordagem Principal - Dados Reais)")
st.write(
    """
    A principal an√°lise foi realizada utilizando o conjunto de dados completo de **1.112 tweets avaliados**. 
    Este conjunto de dados reflete a realidade da coleta, sendo **desbalanceado** (aproximadamente 69% Negativos e 31% Positivos).
    
    O processo seguiu os seguintes passos:
    1.  **Pr√©-processamento do Texto:** Limpeza de dados (acentos, links, stopwords, etc.).
    2.  **Vetoriza√ß√£o com TF-IDF:** Transforma√ß√£o do texto em vetores num√©ricos.
    3.  **Divis√£o Estratificada (80/20):** Separa√ß√£o dos dados em treino e teste, mantendo a propor√ß√£o 70/30 de classes em ambos.
    4.  **Treinamento com Corre√ß√£o de Vi√©s:** Os modelos foram treinados usando o par√¢metro `class_weight='balanced'`, que "pune" mais o modelo por errar na classe minorit√°ria (Positivo), for√ßando-o a dar mais aten√ß√£o a ela.
    """
)

st.header("Resultados (Abordagem Principal - Dados Reais)")

# Criando o DataFrame com os resultados
data = {
    'Modelo': ['Naive Bayes', 'Regress√£o Log√≠stica', 'SVM (LinearSVC)', 'Random Forest', 'LightGBM'],
    'Acur√°cia Geral': ['74%', '75%', '74%', '78%', '70%'],
    'Recall (Positivo)': [0.29, 0.56, 0.54, 0.44, 0.57],
    'Precis√£o (Positivo)': [0.74, 0.61, 0.60, 0.76, 0.53],
    'F1-Score (Positivo)': [0.41, 0.58, 0.57, 0.56, 0.55]
}
df_results = pd.DataFrame(data)

st.write("A tabela abaixo resume a performance dos modelos testados no cen√°rio do mundo real. O **F1-Score (Positivo)** foi a m√©trica principal para a escolha do melhor modelo.")

# Fun√ß√£o para destacar o maior valor na coluna
def highlight_max(s):
    # Converte a string para float para compara√ß√£o
    s_numeric = pd.to_numeric(s, errors='coerce')
    is_max = s_numeric == s_numeric.max()
    return ['background-color: #28a745; color: white' if v else '' for v in is_max]

st.dataframe(
    df_results.style.apply(highlight_max, subset=['F1-Score (Positivo)']),
    use_container_width=True,
    hide_index=True
)

st.subheader("üèÜ Modelo Vencedor (Mundo Real): Regress√£o Log√≠stica")
st.success(
    """
    O modelo de **Regress√£o Log√≠stica** foi selecionado como o melhor para a tarefa real. 
    Ele apresentou o F1-Score mais alto para a classe minorit√°ria (0.58), indicando o melhor 
    equil√≠brio entre a capacidade de encontrar tweets positivos (`Recall`) e a precis√£o de suas 
    classifica√ß√µes (`Precision`), **utilizando 100% dos dados coletados**.
    """
)

st.markdown("---")

# --- SE√á√ÉO 2: O EXPERIMENTO DE LABORAT√ìRIO (BASE BALANCEADA) ---

st.header("üî¨ An√°lise de Laborat√≥rio: Teste com Base Balanceada (50/50)")
st.write(
    """
    Para entender melhor o comportamento fundamental de cada algoritmo sem o vi√©s do desbalanceamento, 
    realizamos um segundo experimento. Criamos um novo dataset perfeitamente balanceado 
    contendo **250 tweets positivos e 250 negativos** (total de 500 amostras), 
    processo chamado de **Under-sampling** (subamostragem).

    Treinamos e testamos os mesmos algoritmos nesta base 50/50.
    """
)

st.subheader("Resultados Comparativos (Dataset Balanceado 50/50)")

# Criando o DataFrame com os resultados do novo experimento
data_balanced = {
    'Modelo': ['Random Forest', 'Regress√£o Log√≠stica', 'SVM (LinearSVC)', 'LightGBM', 'Naive Bayes'],
    'Acur√°cia Geral': ['74.00%', '72.00%', '71.00%', '63.00%', '58.00%'],
    'F1-Score (M√©dia)': [0.74, 0.72, 0.71, 0.63, 0.55],
    'F1-Score (Positivo)': [0.70, 0.69, 0.70, 0.60, 0.67],
    'F1-Score (Negativo)': [0.77, 0.75, 0.72, 0.65, 0.43]
}
df_results_balanced = pd.DataFrame(data_balanced)

st.dataframe(
    df_results_balanced.style.apply(highlight_max, subset=['F1-Score (M√©dia)']),
    use_container_width=True,
    hide_index=True
)

st.subheader("üèÜ Conclus√£o do Experimento (Balanceado vs. Real)")
st.info(
    """
    **O que este experimento nos ensina?**

    1.  **O Vencedor do "Laborat√≥rio":** No cen√°rio 50/50, o **Random Forest** foi o campe√£o. Ele provou ser o algoritmo mais "inteligente", aprendendo melhor os padr√µes quando os dados estavam perfeitamente balanceados.

    2.  **Por que a Regress√£o Log√≠stica √© a Escolha Final:** Embora o Random Forest tenha vencido o teste de laborat√≥rio, ele **perdeu 515 tweets negativos** (765 - 250) que foram descartados no processo de under-sampling.

    3.  **Veredito:** A abordagem da **Regress√£o Log√≠stica** no dataset completo (primeiro teste) √© a **melhor solu√ß√£o final**, pois ela usou **toda a informa√ß√£o dispon√≠vel** (1.112 tweets) e, atrav√©s da t√©cnica `class_weight='balanced'`, conseguiu corrigir o vi√©s do desbalanceamento sem descartar dados valiosos.
    """
)